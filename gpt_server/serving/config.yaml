# 后台启动 nohup sh start.sh > gptserver.log &
serve_args:
  host: 0.0.0.0
  port: 8082

models:
  chatglm3:  #自定义的模型名称
    alias: null # 别名     例如  gpt4,gpt3
    enable: true  # false true
    model_name_or_path: /home/dev/model/chatglm3-6b/
    model_type: chatglm3  # qwen  chatglm3 yi internlm
    work_mode: hf  # vllm hf

    workers:
    - gpus:
      # - 1
      - 2
      # - 3
    # - gpus:
    #   - 0
  
  qwen:  #自定义的模型名称
    alias: null # 别名     例如  gpt4,gpt3
    enable: false  # false true
    # model_name_or_path: /home/dev/model/qwen/Qwen1___5-14B-Chat/ 
    model_name_or_path: /home/dev/model/qwen/Qwen-14B-Chat/  # Qwen 1.0
    model_type: qwen  # qwen  chatglm3 yi internlm
    work_mode: hf  # vllm hf

    workers:
    - gpus:
      # - 1
      - 2
  yi:  #自定义的模型名称
    alias: null # 别名     例如  gpt4,gpt3
    enable: false  # false true
    model_name_or_path: /home/dev/model/01ai/Yi-34B-Chat/
    model_type: yi  # qwen  chatglm3 yi internlm
    work_mode: hf  # vllm hf

    workers:
    - gpus:
      - 2
      # - 0

  internlm:  #自定义的模型名称
    alias: null # 别名     例如  gpt4,gpt3
    enable: false  # false true
    model_name_or_path: /home/dev/model/Shanghai_AI_Laboratory/internlm2-chat-7b/
    model_type: internlm  # qwen  chatglm3 yi internlm
    work_mode: hf  # vllm hf

    workers:
    - gpus:
      - 2
      # - 0
    
  # Embedding 模型
  embedding:
    alias: piccolo-base-zh # 别名   
    enable: false  # false true
    model_name_or_path: /home/dev/model/assets/embeddings/sensenova/piccolo-base-zh/
    model_type: embedding
    work_mode: hf

    workers:
    - gpus:
      - 0








